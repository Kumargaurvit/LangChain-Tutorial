{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353e11a7",
   "metadata": {},
   "source": [
    "#### Messages\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM.\n",
    "Messages are objects that contain:\n",
    " - Role - Identifies the message type (e.g. system, user)\n",
    " - Content - Represents the actual content of the message (like text, images, audio, documents, etc.)\n",
    " - Metadata - Optional fields such as response information, message IDs, and token usage\n",
    "\n",
    "LangChain provides a standard message type that works across all model providers, ensuring consistent behavior regardless of the model being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3357c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e725ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d025bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001D78B40E350>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D78F5D79D0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model_name=\"llama-3.3-70b-versatile\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8c541",
   "metadata": {},
   "source": [
    "### Text Prompts\n",
    "Text prompts are strings - ideal for straightforward generation tasks where you don’t need to retain conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e833b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Hello\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07154424",
   "metadata": {},
   "source": [
    "Use text prompts when:\n",
    "- You have a single, standalone request\n",
    "- You don’t need conversation history\n",
    "- You want minimal code complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08060950",
   "metadata": {},
   "source": [
    "### Message Prompts\n",
    "Alternatively, you can pass in a list of messages to the model by providing a list of message objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555b987",
   "metadata": {},
   "source": [
    "Message types\n",
    "- System message - Tells the model how to behave and provide context for interactions\n",
    "- Human message - Represents user input and interactions with the model\n",
    "- AI message - Responses generated by the model, including text content, tool calls, and metadata\n",
    "- Tool message - Represents the outputs of tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840ada5",
   "metadata": {},
   "source": [
    "### System Message\n",
    "A SystemMessage represent an initial set of instructions that primes the model’s behavior. You can use a system message to set the tone, define the model’s role, and establish guidelines for responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220e548",
   "metadata": {},
   "source": [
    "### Human Message\n",
    "A HumanMessage represents user input and interactions. They can contain text, images, audio, files, and any other amount of multimodal content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19423953",
   "metadata": {},
   "source": [
    "### AI Message\n",
    "An AIMessage represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc589046",
   "metadata": {},
   "source": [
    "### Tool Message\n",
    "For models that support tool calling, AI messages can contain tool calls. Tool messages are used to pass the results of a single tool execution back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d777c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Generative AI, an agent refers to a software program that uses artificial intelligence (AI) and machine learning (ML) algorithms to generate content, make decisions, or interact with its environment. Agents can be designed to perform various tasks, such as generating text, images, music, or even entire virtual worlds.\n",
      "\n",
      "There are several types of agents in Generative AI, including:\n",
      "\n",
      "1. **Reinforcement Learning (RL) Agents**: These agents learn to take actions in an environment to maximize a reward signal. They are commonly used in game-playing, robotics, and autonomous vehicles.\n",
      "2. **Generative Adversarial Network (GAN) Agents**: These agents use a two-player game framework to generate new, synthetic data that resembles existing data. GANs are widely used for image and video generation, as well as text-to-image synthesis.\n",
      "3. **Variational Autoencoder (VAE) Agents**: These agents use a probabilistic approach to learn a continuous and structured representation of data. VAEs are often used for image and text generation, as well as anomaly detection.\n",
      "4. **Evolutionary Agents**: These agents use evolutionary algorithms, such as genetic algorithms or evolution strategies, to search for optimal solutions to complex problems. Evolutionary agents are often used in areas like robotics, finance, and video game development.\n",
      "5. **Hybrid Agents**: These agents combine multiple AI and ML techniques, such as RL, GANs, and VAEs, to generate content or make decisions. Hybrid agents are often used in applications like chatbots, virtual assistants, and game development.\n",
      "6. **Cognitive Agents**: These agents use cognitive architectures, such as SOAR or LIDA, to simulate human-like reasoning and decision-making. Cognitive agents are often used in areas like human-computer interaction, robotics, and autonomous systems.\n",
      "7. **Swarm Agents**: These agents are designed to work together in a decentralized manner, often using techniques like flocking or swarm intelligence. Swarm agents are commonly used in areas like robotics, traffic simulation, and crowd modeling.\n",
      "8. **Neural Agents**: These agents use neural networks, such as recurrent neural networks (RNNs) or transformers, to generate content or make decisions. Neural agents are widely used in areas like natural language processing, computer vision, and speech recognition.\n",
      "\n",
      "These types of agents are not mutually exclusive, and many modern Generative AI systems combine elements from multiple categories to achieve their goals. The specific type of agent used depends on the application, the complexity of the task, and the desired outcome.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a Generative AI engineer expert.\"),\n",
    "    HumanMessage(content=\"What are Agents in Generative AI and what are their types?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "558acfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction to REST API**\n",
      "==========================\n",
      "\n",
      "A REST (Representational State of Resource) API is an architectural style for designing networked applications. It's based on the idea of resources, which are identified by URIs, and can be manipulated using a fixed set of operations.\n",
      "\n",
      "**Key Characteristics of REST API:**\n",
      "\n",
      "* **Resource-based**: Everything in REST is a resource (e.g., users, products, orders).\n",
      "* **Client-Server Architecture**: The client and server are separate, with the client making requests to the server to access or modify resources.\n",
      "* **Stateless**: The server does not maintain any information about the client state.\n",
      "* **Cacheable**: Responses from the server can be cached by the client to reduce the number of requests.\n",
      "* **Uniform Interface**: A uniform interface is used to communicate between client and server, which includes HTTP methods (GET, POST, PUT, DELETE), URI, HTTP headers, and query parameters.\n",
      "\n",
      "**Creating a REST API using Python and Flask**\n",
      "--------------------------------------------\n",
      "\n",
      "Here's an example of creating a simple REST API using Python and Flask:\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# Sample in-memory data store\n",
      "users = [\n",
      "    {\"id\": 1, \"name\": \"John Doe\", \"email\": \"john@example.com\"},\n",
      "    {\"id\": 2, \"name\": \"Jane Doe\", \"email\": \"jane@example.com\"}\n",
      "]\n",
      "\n",
      "# GET /users\n",
      "@app.route('/users', methods=['GET'])\n",
      "def get_users():\n",
      "    return jsonify(users)\n",
      "\n",
      "# GET /users/:id\n",
      "@app.route('/users/<int:user_id>', methods=['GET'])\n",
      "def get_user(user_id):\n",
      "    user = next((user for user in users if user[\"id\"] == user_id), None)\n",
      "    if user is None:\n",
      "        return jsonify({\"error\": \"User not found\"}), 404\n",
      "    return jsonify(user)\n",
      "\n",
      "# POST /users\n",
      "@app.route('/users', methods=['POST'])\n",
      "def create_user():\n",
      "    new_user = {\n",
      "        \"id\": len(users) + 1,\n",
      "        \"name\": request.json[\"name\"],\n",
      "        \"email\": request.json[\"email\"]\n",
      "    }\n",
      "    users.append(new_user)\n",
      "    return jsonify(new_user), 201\n",
      "\n",
      "# PUT /users/:id\n",
      "@app.route('/users/<int:user_id>', methods=['PUT'])\n",
      "def update_user(user_id):\n",
      "    user = next((user for user in users if user[\"id\"] == user_id), None)\n",
      "    if user is None:\n",
      "        return jsonify({\"error\": \"User not found\"}), 404\n",
      "    user[\"name\"] = request.json.get(\"name\", user[\"name\"])\n",
      "    user[\"email\"] = request.json.get(\"email\", user[\"email\"])\n",
      "    return jsonify(user)\n",
      "\n",
      "# DELETE /users/:id\n",
      "@app.route('/users/<int:user_id>', methods=['DELETE'])\n",
      "def delete_user(user_id):\n",
      "    user = next((user for user in users if user[\"id\"] == user_id), None)\n",
      "    if user is None:\n",
      "        return jsonify({\"error\": \"User not found\"}), 404\n",
      "    users.remove(user)\n",
      "    return jsonify({\"message\": \"User deleted\"})\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run(debug=True)\n",
      "```\n",
      "\n",
      "**Running the API**\n",
      "------------------\n",
      "\n",
      "To run the API, save the above code in a file named `app.py` and execute it using `python app.py`. You can then use a tool like `curl` or a REST client like Postman to test the API endpoints.\n",
      "\n",
      "**Example Use Cases**\n",
      "--------------------\n",
      "\n",
      "*   **GET /users**: `curl http://localhost:5000/users`\n",
      "*   **GET /users/:id**: `curl http://localhost:5000/users/1`\n",
      "*   **POST /users**: `curl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"New User\", \"email\": \"new@example.com\"}' http://localhost:5000/users`\n",
      "*   **PUT /users/:id**: `curl -X PUT -H \"Content-Type: application/json\" -d '{\"name\": \"Updated User\"}' http://localhost:5000/users/1`\n",
      "*   **DELETE /users/:id**: `curl -X DELETE http://localhost:5000/users/1`\n"
     ]
    }
   ],
   "source": [
    "# Detailed info to the LLM Model through the system message\n",
    "\n",
    "system_msg = SystemMessage(\n",
    "    \"\"\"\n",
    "    You are a senior Python developer with expertise in web frameworks.\n",
    "    Always provide code examples and explain your reasoning.\n",
    "    Be concise but thorough in your explanation.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(content=\"What is a REST API and How do I create one?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4c2e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Metadata\n",
    "human_msg = HumanMessage(\n",
    "    content = \"Hello!\",\n",
    "    name = \"gaurvit\", # Optional: Identify different users\n",
    "    id = \"gaurvit_1\" # Optional: Unique identifier for tracing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477991f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 37, 'total_tokens': 62, 'completion_time': 0.054052683, 'completion_tokens_details': None, 'prompt_time': 0.001052421, 'prompt_tokens_details': None, 'queue_time': 0.057459379, 'total_time': 0.055105104}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bd757-7df4-73c2-8ffa-da3744fa487d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 37, 'output_tokens': 25, 'total_tokens': 62}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke([human_msg])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac114b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate 3 times 2023, I'll multiply the numbers:\n",
      "\n",
      "3 × 2023 = 6069\n",
      "\n",
      "So the answer is 6069. Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "# Create an AI Mesage manually (eg. conversation history)\n",
    "ai_msg = AIMessage(content=\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Can you help me?\"),\n",
    "    ai_msg,\n",
    "    HumanMessage(content=\"Great! What is 3 times 2023\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c6cfcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 77, 'output_tokens': 44, 'total_tokens': 121}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749541f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in New Delhi is sunny with a temperature of 72°F (22°C). However, please note that weather conditions can change rapidly, and it's always a good idea to check the latest forecast for the most up-to-date information.\n",
      "\n",
      "If you're looking for more detailed information, I can suggest some weather websites or apps that provide real-time updates, such as AccuWeather or the Indian Meteorological Department's website. Would you like me to provide more information or suggest some resources?\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# After a model makes a tool call\n",
    "# (Here, we demonstrate manually creating the messages for brevity)\n",
    "ai_message = AIMessage(\n",
    "    content = [],\n",
    "    tool_calls = [{\n",
    "        \"name\" : \"get_weather\",\n",
    "        \"args\" : {\"city\" : \"New Delhi\"},\n",
    "        \"id\" : \"tool_call_1\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunnny, 72F\"\n",
    "tool_message = ToolMessage(\n",
    "    tool_call_id = \"tool_call_1\", # Must match id from AIMessage\n",
    "    content = weather_result\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the weather in New Delhi?\"),\n",
    "    ai_message, # Model tool call\n",
    "    tool_message # Tool execution result\n",
    "]\n",
    "\n",
    "# Generating response by invoking the model with messages\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2548e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
