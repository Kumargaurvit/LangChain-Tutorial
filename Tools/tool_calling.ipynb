{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e958497",
   "metadata": {},
   "source": [
    "### Tool Calling in LangChain\n",
    "\n",
    "Tool Calling is the process where the LLM (language model) decides, during a conversation or task, that it needs to use a specific tool (function) and generates a structured output with:\n",
    "\n",
    "- The name of the tool\n",
    "- The arguments to call it with\n",
    "\n",
    "The LLM does not actually run the tool it just suggests the tool and the input arguments. The actual execution is handled by LangChain or you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Creating a Custom Tool\n",
    "@tool\n",
    "def multiply(a: float, b: float)->float:\n",
    "    \"\"\"Multiplies two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77dc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afa0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000181E3D263C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000181E3D270E0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "# LLM Model Initialization using GROQ\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122caebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000181E3D263C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000181E3D270E0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiplies two numbers', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binding Tool with the LLM Model\n",
    "llm_with_tool = llm.bind_tools([multiply])\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f29589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': '30p3vrkzf', 'function': {'arguments': '{\"a\":7,\"b\":8}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 221, 'total_tokens': 240, 'completion_time': 0.035372549, 'completion_tokens_details': None, 'prompt_time': 0.017998297, 'prompt_tokens_details': None, 'queue_time': 0.052851814, 'total_time': 0.053370846}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bfb44-a033-7541-82f1-731389f928a2-0' tool_calls=[{'name': 'multiply', 'args': {'a': 7, 'b': 8}, 'id': '30p3vrkzf', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 221, 'output_tokens': 19, 'total_tokens': 240}\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_tool.invoke(\"What is 7 times 8\")\n",
    "\n",
    "print(response) # We can see in the output that the LLM made a tool call to the multiply tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': 7, 'b': 8},\n",
       " 'id': 'haj2rcpgp',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"What is 7 times 8\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f153d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
